{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from haversine import haversine, haversine_vector, Unit\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To supress the scientific notation for easier reading.\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Development\n",
    "\n",
    "In developing the code, three main tests have been completed within one region: Amhara. The first at a very micro level with a custom dummy dataset with only two primary schools and 2 proposed secondary schools. The second is for one woreda/district with 21 primary schools and two secondary schools, whereby 5 secondary schools are proposed. The final test was a region wide test with 1765 primary schools and 1658 secondary schools, with 5 new secondary schools proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which test to perform\n",
    "declare_test = 2 # micro test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare key variables according to the test being performed.\n",
    "region = 'Amhara' # Test Amhara region\n",
    "woreda = 'ET030908'\n",
    "\n",
    "if declare_test == 1: # for micro test\n",
    "    # read in the prepared dataset. Evaluate point data to make it readible by geopandas\n",
    "    df = pd.read_csv('data/test_dataset2.csv', converters={'point': pd.eval})\n",
    "    proposed_schools= 2\n",
    "    gdf_woreda = gpd.read_file('eth_shape_files/json/eth_admin3v2.json')\n",
    "    gdf_woreda_shp = gdf_woreda.loc[gdf_woreda['ADM3_PCODE']==woreda]['geometry'].reset_index(drop=True)\n",
    "    df = df.loc[df['ADM3_PCODE'] == woreda]\n",
    "    bounds = gdf_woreda_shp.bounds\n",
    "elif declare_test == 2:\n",
    "    df = pd.read_csv('data/test_dataset.csv', converters={'point': pd.eval})\n",
    "    proposed_schools= 5\n",
    "    gdf_woreda = gpd.read_file('eth_shape_files/json/eth_admin3v2.json')\n",
    "    gdf_woreda_shp = gdf_woreda.loc[gdf_woreda['ADM3_PCODE']==woreda]['geometry'].reset_index(drop=True)\n",
    "    df = df.loc[df['ADM3_PCODE'] == woreda]\n",
    "    bounds = gdf_woreda_shp.bounds\n",
    "else:\n",
    "    proposed_schools= 5\n",
    "    df = pd.read_csv('data/clean_dataset.csv', converters={'point': pd.eval})\n",
    "    # limit geojson to only selected region\n",
    "    # limit clean dataset to only selected region\n",
    "    gdf_region = gpd.read_file('eth_shape_files/json//eth_admin1v2.json') # read in geojson\n",
    "    gdf_region_shp = gdf_region.loc[gdf_region['ADM1_EN']==region]['geometry'].reset_index(drop=True)\n",
    "    df = df.loc[df['region'] == region]\n",
    "    bounds = gdf_region_shp.bounds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.71371939, 36.68932805, 10.71371939, 36.68932805, 10.71371939,\n",
       "        36.68932805, 10.71371939, 36.68932805, 10.71371939, 36.68932805],\n",
       "       [10.96477258, 36.96973029, 10.96477258, 36.96973029, 10.96477258,\n",
       "        36.96973029, 10.96477258, 36.96973029, 10.96477258, 36.96973029]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish boundaries based on the bounds of region or woreda.\n",
    "# Latitude is the Y axis, longitude is the X axis.\n",
    "\n",
    "lat_bounds = bounds[['miny','maxy']].to_numpy(dtype=float)[0]\n",
    "lon_bounds = bounds[['minx','maxx']].to_numpy(dtype=float)[0]\n",
    "bounds = np.array([[lat_bounds[0], lon_bounds[0]], [lat_bounds[1], lon_bounds[1]]])\n",
    "# array - [[lower lat bounds, lower lon bounds],[upper lat bounds, upper lon bounds]]\n",
    "# CMA expects a list of size 2 for bounds\n",
    "x1y1 = np.repeat([bounds[0,:]],proposed_schools, axis=0).flatten()\n",
    "x2y2 = np.repeat([bounds[1,:]],proposed_schools, axis=0).flatten()\n",
    "boundsxy = np.array([x1y1,x2y2])\n",
    "boundsxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset arrays required as input for enrollment function.\n",
    "# 1. Primary school enrollment data\n",
    "# 2. Primary school location data: lat lon point data. \n",
    "# 3. Secondary schoool location data: lat lon point data. \n",
    "# 4. Secondary school enrollment data. Potentially required for calibration function.\n",
    "\n",
    "df_prim = df.loc[ (df['gr_offer'] == 'G.1-8') | (df['gr_offer'] == 'G.5-8')]\n",
    "df_prim_enroll = df_prim['grade5_8'].reset_index(drop=True).to_numpy(dtype=float)\n",
    "df_prim_loc = df_prim['point'].reset_index(drop=True).to_numpy()\n",
    "df_prim_loc = np.array([np.array(i) for i in df_prim_loc], dtype=float)\n",
    "\n",
    "df_sec = df.loc[ (df['gr_offer'] == 'G. 9-10') | (df['gr_offer'] == 'G. 9-12')]\n",
    "df_sec_loc = df_sec['point'].reset_index(drop=True).to_numpy()\n",
    "df_sec_enroll = df_sec['grade9_10'].reset_index(drop=True).to_numpy(dtype=float)\n",
    "df_sec_loc = np.array([np.array(i) for i in df_sec_loc], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sec = len(df_sec_enroll)+ proposed_schools\n",
    "total_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_woreda(vec):\n",
    "    # lat = y, x=lon\n",
    "    vec = gpd.points_from_xy(vec[:, 1], vec[:, 0])\n",
    "    return vec.within(gdf_woreda_shp[0]).all()\n",
    "            \n",
    "def check_region(vec):\n",
    "    # lat = y, x=lon\n",
    "    vec = gpd.points_from_xy(vec[:, 1], vec[:, 0])\n",
    "    return vec.within(gdf_region_shp[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(distance, enrollment):\n",
    "    min_walk = 2 # distance not a factor issuing enrollment until 2km\n",
    "    max_walk = 5 # distance greater than 5km assumes zero enrollment\n",
    "    answer = np.where(distance<min_walk, enrollment,\n",
    "             np.where(distance>max_walk, 0,\n",
    "                     enrollment*(1-(distance-min_walk)/(max_walk-min_walk)))\n",
    "            )\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_enroll(prim_loc, x, prim_enroll):\n",
    "    distance = haversine_vector(prim_loc, x, Unit.KILOMETERS, comb=True)\n",
    "    min_d = np.min(distance, axis=0) # array with minimum distance from each primacy school to every secondary.\n",
    "    shaped_enroll = shape(min_d, prim_enroll)\n",
    "    return np.sum(shaped_enroll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Objective Function with the shape function included.\n",
    "def f(x):\n",
    "    x = np.append(df_sec_loc, x).reshape(total_sec,2) #  add new schools to existing and reshape\n",
    "    test_case = expected_enroll(df_prim_loc, x, df_prim_enroll)\n",
    "    return test_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random points within regional or district boundaries boundaries.\n",
    "\n",
    "def create_random_sp(sp_type):\n",
    "    if sp_type == 'region':\n",
    "        shape_file = gdf_region_shp[0]\n",
    "    else:\n",
    "        shape_file = gdf_woreda_shp[0]\n",
    "    sp_in_bounds = False\n",
    "    while sp_in_bounds == False:\n",
    "        sp1 = np.random.uniform(low=lat_bounds[0], high=lat_bounds[1], size=proposed_schools)\n",
    "        sp2 = np.random.uniform(low=lon_bounds[0], high=lon_bounds[1], size=proposed_schools)\n",
    "        sp = np.vstack((sp1, sp2)).T\n",
    "        sp_points = gpd.points_from_xy(sp[:, 1], sp[:, 0])\n",
    "        if sp_points.within(shape_file).all():\n",
    "            sp_in_bounds = True\n",
    "            return sp.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_woreda_shp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_points.within(shape_file).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(f, n, test_type):\n",
    "    x = [create_random_sp(test_type) for _ in range(n)] \n",
    "    fx = [(f(xi), xi) for xi in x]\n",
    "    best_f, best_solution = max(fx, key=lambda x:x[0])\n",
    "    return best_f, best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time fx = [random_search(f, 1000, 'woreda') for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.4200536 , 0.97208858, 4.32832206, 5.29183205, 9.11916044,\n",
       "       5.27713026, 1.73032317, 3.33592388, 5.22039308, 9.74686057,\n",
       "       4.88778134, 4.00496738, 0.756862  , 7.40811787, 4.05068789,\n",
       "       7.28259465, 9.52187629, 4.88278866, 5.29026977, 4.59711784,\n",
       "       2.82367034])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.89509746, 36.83795863, 10.90310309, 36.85796824, 10.84827089,\n",
       "       36.77392375, 10.73741988, 36.90180524, 10.7663454 , 36.90314876])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.81665275, 36.88701445, 10.83406083, 36.76029432, 10.82165553,\n",
       "       36.92905401, 10.78225412, 36.86877747, 10.9070319 , 36.76519061])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = create_random_sp('woreda')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.4200536 , 0.97208858, 4.32832206, 5.29183205, 9.11916044,\n",
       "       5.27713026, 1.73032317, 3.33592388, 5.22039308, 9.74686057,\n",
       "       4.88778134, 4.00496738, 0.756862  , 7.40811787, 4.05068789,\n",
       "       7.28259465, 9.52187629, 4.88278866, 5.29026977, 4.59711784,\n",
       "       2.82367034])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEI = 0\n",
    "current_ps_distance = df_prim['nearest_lwr_sec'].to_numpy()\n",
    "current_ps_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.41277497, 13.24229097,  8.12004878,  9.01846775,  5.9165214 ,\n",
       "        8.91690618,  3.46359133, 20.28516042,  6.06932388, 15.75621063,\n",
       "        8.08088888,  8.72017463,  4.11585991,  2.64399233, 18.75245616,\n",
       "        5.40520203,  9.86132162, 11.59902135,  3.89821598, 14.68540056,\n",
       "       12.17668457])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = haversine_vector(df_prim_loc, x, Unit.KILOMETERS, comb=True)[0]\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6, 12, 13, 18], dtype=int64),)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_than5 = np.where(distance < 5)\n",
    "less_than5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = np.where(distance[less_than5] < current_distance[less_than5])\n",
    "EEI += np.sum(shape(distance[ff], df_prim_enroll[ff]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then i need to find number of primary schools that are \n",
    "\n",
    "# less_than5.flatten() < current_distance\n",
    "# df_prim_enroll[distance.flatten() < current_distance]\n",
    "# np.where(distance > )\n",
    "# np.where(distance < 5)\n",
    "# EEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.71112112, 3.26969206, 3.2762255 ])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance[less_than5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-118-1ad0532a8cd8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-118-1ad0532a8cd8>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    np.where(distance[less_than5] < current_distance[less_than5], EEI +=shape(distance[less_than5], df_prim_enroll[less_than5]))\u001b[0m\n\u001b[1;37m                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "np.where(distance[less_than5] < current_distance[less_than5], EEI +="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 208.        , 5767.69313345,   64.35424813])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-6e81488de9f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mless_than5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcurrent_distance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mless_than5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mEEI\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mless_than5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_prim_enroll\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mless_than5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 13 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-a902ab698b07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdistance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mless_than5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 13 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "distance[less_than5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 13 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-6e81488de9f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mless_than5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcurrent_distance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mless_than5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mEEI\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mless_than5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_prim_enroll\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mless_than5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 13 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.71112112, 3.26969206, 3.2762255 ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.flatten()[less_than5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.044768  ],\n",
       "       [15.87673969],\n",
       "       [ 9.16207275],\n",
       "       [11.63796154],\n",
       "       [ 7.40260374],\n",
       "       [11.38018826],\n",
       "       [ 5.86725427],\n",
       "       [22.65573425],\n",
       "       [ 8.73104073],\n",
       "       [17.74857666],\n",
       "       [10.69604236],\n",
       "       [10.84469902],\n",
       "       [ 6.08722119],\n",
       "       [ 1.71112112],\n",
       "       [21.35137037],\n",
       "       [ 3.26969206],\n",
       "       [ 7.18894129],\n",
       "       [14.19118556],\n",
       "       [ 3.2762255 ],\n",
       "       [17.15517878],\n",
       "       [14.83760664]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEI = 0\n",
    "current_dist_ss = df['distance'].to_numpy() # existing distance to nearest ss for each ps\n",
    "for i in ss:\n",
    "    # calculate distance from proposed secondary to all primary.\n",
    "    ps_d = haversine_distance(i, ps, Unit.KM, comb=true)\n",
    "    ps_feeder = np.where(ps_d < 5) # vector of ps with distance less than 5km to secondary.\n",
    "    # compare distances to existing secondary schools, if less, then pop.\n",
    "    if ps_d > current_dist_ss:\n",
    "        pop(ps_feeder[i]) # remove school from vector.\n",
    "    else:\n",
    "        # subtract the previous enrollment\n",
    "        EEI += shape(ps_d, ps_enrollment) # add ps enrollment to EEI.\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle('Random Search F(2). 4 Outputs with Different Starting Points')\n",
    "\n",
    "for i in range(4):\n",
    "    ax = 'ax'+str(i)\n",
    "    eval(ax).scatter(df_prim_loc[:, 1], df_prim_loc[:, 0], s=df_prim_enroll/100, label=\"Prim\") # s gives size\n",
    "    if(len(df_sec) != 0): eval(ax).scatter(df_sec_loc[:, 1], df_sec_loc[:, 0], s=df_sec_enroll/100, label=\"Secondary\") # s gives size\n",
    "    eval(ax).scatter(fx[i][1][1::2], fx[i][1][::2], s = 35, marker=\"o\", label=\"New Secondary\") # stars for supermarkets\n",
    "    eval(ax).set_title(np.round(fx[i][0],0), fontstyle='italic')\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = (0.01, 0.05, 0.1, 0.12, 0.14, 0.16, 0.18, 0.2, 0.22, 0.24)\n",
    "maxits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcma = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in sigmas:\n",
    "        es = cma.CMAEvolutionStrategy(create_random_sp('woreda'), sigma0=j,\n",
    "                                  inopts={'bounds': boundsxy,'seed':1234})\n",
    "        es.optimize(f, iterations=maxits / es.popsize)\n",
    "        fcma.append((es.result[1], es.result[0], j))\n",
    "        \n",
    "fcma_s = sorted(fcma, key=lambda t: t[0])[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcma_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle('CMA f(1). 4 Outputs with Different Starting Points')\n",
    "\n",
    "for i in range(4):\n",
    "    ax = 'ax'+str(i)\n",
    "    eval(ax).scatter(df_prim_loc[:, 1], df_prim_loc[:, 0], s=df_prim_enroll/100, label=\"Prim\") # s gives size\n",
    "    if(len(df_sec) != 0): eval(ax).scatter(df_sec_loc[:, 1], df_sec_loc[:, 0], s=df_sec_enroll/100, label=\"Secondary\") # s gives size\n",
    "    eval(ax).scatter(fcma_s[i][1][1::2], fcma_s[i][1][::2], s = 35, marker=\"o\", label=\"New Secondary\") # stars for supermarkets\n",
    "    eval(ax).set_title('Max: ' + str(np.round(fcma_s[i][0],0))+ ' . Sigma: ' + str(fcma_s[i][2]), fontstyle='italic')\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcma2 = []\n",
    "maxits= 10000\n",
    "\n",
    "for i in range(4):\n",
    "    for j in sigmas:\n",
    "        es = cma.CMAEvolutionStrategy(get_random_sp(), sigma0=j,\n",
    "                                  inopts={'bounds': boundsxy,'seed':1234})\n",
    "        es.optimize(f2, iterations=maxits / es.popsize)\n",
    "        fcma2.append((es.result[1], es.result[0], j))\n",
    "        \n",
    "fcma2_s = sorted(fcma2, key=lambda t: t[0])[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcma2_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle('CMA F(2). 4 Outputs with Different Starting Points')\n",
    "\n",
    "for i in range(4):\n",
    "    ax = 'ax'+str(i)\n",
    "    eval(ax).scatter(df_prim_loc[:, 1], df_prim_loc[:, 0], s=df_prim_enroll/100, label=\"Prim\") # s gives size\n",
    "    if(len(df_sec) != 0): eval(ax).scatter(df_sec_loc[:, 1], df_sec_loc[:, 0], s=df_sec_enroll/100, label=\"Secondary\") # s gives size\n",
    "    eval(ax).scatter(fcma2_s[i][1][1::2], fcma2_s[i][1][::2], s = 35, marker=\"o\", label=\"New Secondary\") # stars for supermarkets\n",
    "    eval(ax).set_title('Max: ' + str(np.round(fcma2_s[i][0],0))+ ' . Sigma: ' + str(fcma2_s[i][2]), fontstyle='italic')\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosenll = sorted(fcma2, key=lambda t: t[0])[:1]\n",
    "chosenll = chosen[0][1]\n",
    "# chosenll = np.array(np.array_split(chosenll, proposed_schools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_woreda_shp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_random_sp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = gpd.points_from_xy(chosenll[:, 1], chosenll[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_woreda['geometry'] # check all woredas and return corect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosenll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_region = gpd.read_file('eth_shape_files/json//eth_admin1v2.json') # read in geojson\n",
    "gdf_region_shp = gdf_region.loc[gdf_region['ADM1_EN']==region]['geometry'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in chosenll:\n",
    "    for j in gdf_region:\n",
    "        vec.within(gdf_region['geometry'])\n",
    "        \n",
    "#     for j in gdf_woreda:\n",
    "# for i in gdf_woreda:\n",
    "    \n",
    "\n",
    "# vec.within(gdf_woreda['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_woreda(chosenll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosenll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "for i in chosenll:\n",
    "    points += gpd.points_from_xy(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosenll[:1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = [gpd.points_from_xy(i[::2], i[1::2]) for i in chosen]\n",
    "[i.within(gdf_woreda_shp[0]) for i in dd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(vec):\n",
    "    \n",
    "    \n",
    "    region\n",
    "    zone\n",
    "    woreda\n",
    "    \n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_woreda(vec):\n",
    "    # lat = y, x=lon\n",
    "    vec = gpd.points_from_xy(vec[:, 1], vec[:, 0])\n",
    "    return vec.within(gdf_woreda_shp[0]).all()\n",
    "            \n",
    "def check_region(vec):\n",
    "    # lat = y, x=lon\n",
    "    vec = gpd.points_from_xy(vec[:, 1], vec[:, 0])\n",
    "    return vec.within(gdf_region_shp[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find region, zone and woreda of new school. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
