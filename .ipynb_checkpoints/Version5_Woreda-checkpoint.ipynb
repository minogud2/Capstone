{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from haversine import haversine, haversine_vector, Unit\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To supress the scientific notation for easier reading.\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Development\n",
    "\n",
    "In developing the code, three main tests have been completed within one region: Amhara. The first at a very micro level with a custom dummy dataset with only two primary schools and 2 proposed secondary schools. The second is for one woreda/district with 21 primary schools and two secondary schools, whereby 5 secondary schools are proposed. The final test was a region wide test with 1765 primary schools and 1658 secondary schools, with 5 new secondary schools proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which test to perform\n",
    "declare_test = 2 # micro test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare key variables according to the test being performed.\n",
    "region = 'Amhara' # Test Amhara region\n",
    "woreda = 'ET030908'\n",
    "\n",
    "if declare_test == 1: # for micro test\n",
    "    # read in the prepared dataset. Evaluate point data to make it readible by geopandas\n",
    "    df = pd.read_csv('data/test_dataset2.csv', converters={'point': pd.eval})\n",
    "    proposed_schools= 2\n",
    "    gdf_woreda = gpd.read_file('eth_shape_files/json/eth_admin3v2.json')\n",
    "    gdf_woreda_shp = gdf_woreda.loc[gdf_woreda['ADM3_PCODE']==woreda]['geometry'].reset_index(drop=True)\n",
    "    df = df.loc[df['ADM3_PCODE'] == woreda]\n",
    "    bounds = gdf_woreda_shp.bounds\n",
    "elif declare_test == 2:\n",
    "    df = pd.read_csv('data/test_dataset.csv', converters={'point': pd.eval})\n",
    "    proposed_schools= 5\n",
    "    gdf_woreda = gpd.read_file('eth_shape_files/json/eth_admin3v2.json')\n",
    "    gdf_woreda_shp = gdf_woreda.loc[gdf_woreda['ADM3_PCODE']==woreda]['geometry'].reset_index(drop=True)\n",
    "    df = df.loc[df['ADM3_PCODE'] == woreda]\n",
    "    bounds = gdf_woreda_shp.bounds\n",
    "else:\n",
    "    proposed_schools= 5\n",
    "    df = pd.read_csv('data/clean_dataset.csv', converters={'point': pd.eval})\n",
    "    # limit geojson to only selected region\n",
    "    # limit clean dataset to only selected region\n",
    "    gdf_region = gpd.read_file('eth_shape_files/json//eth_admin1v2.json') # read in geojson\n",
    "    gdf_region_shp = gdf_region.loc[gdf_region['ADM1_EN']==region]['geometry'].reset_index(drop=True)\n",
    "    df = df.loc[df['region'] == region]\n",
    "    bounds = gdf_region_shp.bounds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([10.71371939, 36.68932805, 10.71371939, 36.68932805, 10.71371939,\n",
       "        36.68932805, 10.71371939, 36.68932805, 10.71371939, 36.68932805]),\n",
       " array([10.96477258, 36.96973029, 10.96477258, 36.96973029, 10.96477258,\n",
       "        36.96973029, 10.96477258, 36.96973029, 10.96477258, 36.96973029])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish boundaries based on the bounds of region or woreda.\n",
    "# Latitude is the Y axis, longitude is the X axis.\n",
    "\n",
    "lat_bounds = bounds[['miny','maxy']].to_numpy(dtype=float)[0]\n",
    "lon_bounds = bounds[['minx','maxx']].to_numpy(dtype=float)[0]\n",
    "bounds = np.array([[lat_bounds[0], lon_bounds[0]], [lat_bounds[1], lon_bounds[1]]])\n",
    "# array - [[lower lat bounds, lower lon bounds],[upper lat bounds, upper lon bounds]]\n",
    "# CMA expects a list of size 2 for bounds\n",
    "x1y1 = np.repeat([bounds[0,:]],proposed_schools, axis=0).flatten()\n",
    "x2y2 = np.repeat([bounds[1,:]],proposed_schools, axis=0).flatten()\n",
    "boundsxy = [x1y1,x2y2]\n",
    "boundsxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset arrays required as input for enrollment function.\n",
    "# 1. Primary school enrollment data\n",
    "# 2. Primary school location data: lat lon point data. \n",
    "# 3. Secondary schoool location data: lat lon point data. \n",
    "# 4. Secondary school enrollment data. Potentially required for calibration function.\n",
    "\n",
    "df_prim = df.loc[ (df['gr_offer'] == 'G.1-8') | (df['gr_offer'] == 'G.5-8')]\n",
    "df_prim_enroll = df_prim['grade5_8'].reset_index(drop=True).to_numpy(dtype=float)\n",
    "df_prim_loc = df_prim['point'].reset_index(drop=True).to_numpy()\n",
    "df_prim_loc = np.array([np.array(i) for i in df_prim_loc], dtype=float)\n",
    "\n",
    "df_sec = df.loc[ (df['gr_offer'] == 'G. 9-10') | (df['gr_offer'] == 'G. 9-12')]\n",
    "df_sec_loc = df_sec['point'].reset_index(drop=True).to_numpy()\n",
    "df_sec_enroll = df_sec['grade9_10'].reset_index(drop=True).to_numpy(dtype=float)\n",
    "df_sec_loc = np.array([np.array(i) for i in df_sec_loc], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_woreda(vec):\n",
    "    # lat = y, x=lon\n",
    "    vec = gpd.points_from_xy(vec[:, 1], vec[:, 0])\n",
    "    return vec.within(gdf_woreda_shp[0]).all()\n",
    "            \n",
    "def check_region(vec):\n",
    "    # lat = y, x=lon\n",
    "    vec = gpd.points_from_xy(vec[:, 1], vec[:, 0])\n",
    "    return vec.within(gdf_region_shp[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(distance, enrollment):\n",
    "    min_walk = 2 # distance not a factor issuing enrollment until 2km\n",
    "    max_walk = 5 # distance greater than 5km assumes zero enrollment\n",
    "    answer = np.rint(np.where(distance<min_walk, enrollment,\n",
    "             np.where(distance>max_walk, 0.1, # 0.1 or not?\n",
    "                     enrollment*(1-(distance-min_walk)/(max_walk-min_walk)))\n",
    "            ))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_enroll(prim_loc, x, prim_enroll, sec_loc):\n",
    "    x = np.append(sec_loc, x) # The genotype\n",
    "    x = np.array(np.array_split(x, (len(sec_loc)+proposed_tlschools)))\n",
    "    distance = haversine_vector(prim_loc, x, Unit.KILOMETERS, comb=True)\n",
    "    min_d = np.min(distance, axis=0) # array with minimum distance from each primacy school to every secondary.\n",
    "    return np.sum(min_d*prim_enroll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_enroll2(prim_loc, x, prim_enroll, sec_loc):\n",
    "    x = np.append(sec_loc, x) # The genotype\n",
    "    x = np.array(np.array_split(x, (len(sec_loc)+proposed_schools)))\n",
    "    distance = haversine_vector(prim_loc, x, Unit.KILOMETERS, comb=True)\n",
    "    min_d = np.min(distance, axis=0) # array with minimum distance from each primacy school to every secondary.\n",
    "    shaped_enroll = shape(min_d, prim_enroll)\n",
    "    return np.sum(shaped_enroll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Objective Function\n",
    "def f(x):\n",
    "    test_case = expected_enroll(df_prim_loc, x, df_prim_enroll, df_sec_loc)\n",
    "    return np.round(test_case,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Objective Function with the shape function included.\n",
    "def f2(x):\n",
    "    test_case = expected_enroll2(df_prim_loc, x, df_prim_enroll, df_sec_loc)\n",
    "    return np.round(test_case,3)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create starting points within regional box boundaries.\n",
    "\n",
    "def create_random_sp():\n",
    "    sp1 = np.random.uniform(low=lat_bounds[0], high=lat_bounds[1], size=proposed_schools)\n",
    "    sp2 = np.random.uniform(low=lon_bounds[0], high=lon_bounds[1], size=proposed_schools)\n",
    "    sp = np.vstack((sp1, sp2)).T\n",
    "    return sp\n",
    "\n",
    "# create a random starting point within the target region.\n",
    "def get_random_sp():\n",
    "    sp = create_random_sp()\n",
    "    for i in range(0,10000):\n",
    "        if declare_test == 3:\n",
    "            if check_region(sp) == True:\n",
    "                return sp.flatten()\n",
    "                break\n",
    "            else:\n",
    "                sp = create_random_sp()\n",
    "        else:\n",
    "            if check_woreda(sp) == True:\n",
    "                return sp.flatten()\n",
    "                break\n",
    "            else:\n",
    "                sp = create_random_sp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(f, n):\n",
    "    x = [get_random_sp() for _ in range(n)] \n",
    "    fx = [(f(xi), xi) for xi in x]\n",
    "    best_f, best_solution = min(fx, key=lambda x:x[0])\n",
    "    return best_f, best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proposed_tlschools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ea31a831d5e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-ea31a831d5e2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-0b92067bdf69>\u001b[0m in \u001b[0;36mrandom_search\u001b[1;34m(f, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_random_sp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mbest_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_solution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_solution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-0b92067bdf69>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_random_sp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mbest_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_solution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_solution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-90a3ead4c848>\u001b[0m in \u001b[0;36mf\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# The Objective Function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtest_case\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpected_enroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_prim_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_prim_enroll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_sec_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_case\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-81eda41eca30>\u001b[0m in \u001b[0;36mexpected_enroll\u001b[1;34m(prim_loc, x, prim_enroll, sec_loc)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mexpected_enroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprim_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprim_enroll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msec_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msec_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# The genotype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msec_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mproposed_tlschools\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhaversine_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprim_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKILOMETERS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmin_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# array with minimum distance from each primacy school to every secondary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'proposed_tlschools' is not defined"
     ]
    }
   ],
   "source": [
    "fx = [random_search(f, 10000) for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle('Random Search F(1). 4 Outputs with Different Starting Points')\n",
    "\n",
    "for i in range(4):\n",
    "    ax = 'ax'+str(i)\n",
    "    eval(ax).scatter(df_prim_loc[:, 1], df_prim_loc[:, 0], s=df_prim_enroll/100, label=\"Prim\") # s gives size\n",
    "    if(len(df_sec) != 0): eval(ax).scatter(df_sec_loc[:, 1], df_sec_loc[:, 0], s=df_sec_enroll/100, label=\"Secondary\") # s gives size\n",
    "    eval(ax).scatter(fx[i][1][1::2], fx[i][1][::2], s = 35, marker=\"o\", label=\"New Secondary\") # stars for supermarkets\n",
    "    eval(ax).set_title(np.round(fx[i][0],0), fontstyle='italic')\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx2 = [random_search(f2, 10000) for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle('Random Search F(2). 4 Outputs with Different Starting Points')\n",
    "\n",
    "for i in range(4):\n",
    "    ax = 'ax'+str(i)\n",
    "    eval(ax).scatter(df_prim_loc[:, 1], df_prim_loc[:, 0], s=df_prim_enroll/100, label=\"Prim\") # s gives size\n",
    "    if(len(df_sec) != 0): eval(ax).scatter(df_sec_loc[:, 1], df_sec_loc[:, 0], s=df_sec_enroll/100, label=\"Secondary\") # s gives size\n",
    "    eval(ax).scatter(fx2[i][1][1::2], fx2[i][1][::2], s = 35, marker=\"o\", label=\"New Secondary\") # stars for supermarkets\n",
    "    eval(ax).set_title(np.round(fx2[i][0],0), fontstyle='italic')\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = (0.01, 0.05, 0.1, 0.12, 0.14, 0.16, 0.18, 0.2, 0.22, 0.24)\n",
    "maxits = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcma = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in sigmas:\n",
    "        es = cma.CMAEvolutionStrategy(get_random_sp(), sigma0=j,\n",
    "                                  inopts={'bounds': boundsxy,'seed':1234})\n",
    "        es.optimize(f, iterations=maxits / es.popsize)\n",
    "        fcma.append((es.result[1], es.result[0], j))\n",
    "        \n",
    "fcma_s = sorted(fcma, key=lambda t: t[0])[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcma_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle('CMA f(1). 4 Outputs with Different Starting Points')\n",
    "\n",
    "for i in range(4):\n",
    "    ax = 'ax'+str(i)\n",
    "    eval(ax).scatter(df_prim_loc[:, 1], df_prim_loc[:, 0], s=df_prim_enroll/100, label=\"Prim\") # s gives size\n",
    "    if(len(df_sec) != 0): eval(ax).scatter(df_sec_loc[:, 1], df_sec_loc[:, 0], s=df_sec_enroll/100, label=\"Secondary\") # s gives size\n",
    "    eval(ax).scatter(fcma_s[i][1][1::2], fcma_s[i][1][::2], s = 35, marker=\"o\", label=\"New Secondary\") # stars for supermarkets\n",
    "    eval(ax).set_title('Max: ' + str(np.round(fcma_s[i][0],0))+ ' . Sigma: ' + str(fcma_s[i][2]), fontstyle='italic')\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcma2 = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in sigmas:\n",
    "        es = cma.CMAEvolutionStrategy(get_random_sp(), sigma0=j,\n",
    "                                  inopts={'bounds': boundsxy,'seed':1234})\n",
    "        es.optimize(f2, iterations=maxits / es.popsize)\n",
    "        fcma2.append((es.result[1], es.result[0], j))\n",
    "        \n",
    "fcma2_s = sorted(fcma2, key=lambda t: t[0])[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle('CMA F(2). 4 Outputs with Different Starting Points')\n",
    "\n",
    "for i in range(4):\n",
    "    ax = 'ax'+str(i)\n",
    "    eval(ax).scatter(df_prim_loc[:, 1], df_prim_loc[:, 0], s=df_prim_enroll/100, label=\"Prim\") # s gives size\n",
    "    if(len(df_sec) != 0): eval(ax).scatter(df_sec_loc[:, 1], df_sec_loc[:, 0], s=df_sec_enroll/100, label=\"Secondary\") # s gives size\n",
    "    eval(ax).scatter(fcma2_s[i][1][1::2], fcma2_s[i][1][::2], s = 35, marker=\"o\", label=\"New Secondary\") # stars for supermarkets\n",
    "    eval(ax).set_title('Max: ' + str(np.round(fcma2_s[i][0],0))+ ' . Sigma: ' + str(fcma2_s[i][2]), fontstyle='italic')\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count feeder schools. \n",
    "# hub and spoke graph. \n",
    "# function to calculate overall enrollment of new feeder schools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(lower_prim_df, lat=\"lat\", lon=\"lon\",color='lwr_prim_dist_to_upp_prim_school_km',\n",
    "                        color_continuous_scale=cmap,\n",
    "                        size = 'grade1_4',\n",
    "                        range_color=[0,20], zoom=5,\n",
    "                        center={'lat':9.1450,'lon': 40.4897},\n",
    "                        hover_name=\"school_name\",\n",
    "                        hover_data = ['region', 'grade1_4','lwr_prim_dist_to_upp_prim_school_km'],\n",
    "                         text=lower_prim_df['ADM1_EN']\n",
    "                       )\n",
    "\n",
    "fig.update_traces(textposition='top center')\n",
    "\n",
    "fig.. \n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}),\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
